import json
import logging
from typing import Dict, Any, List, Optional

# Import constants and classes from other modules
from MassAudit_Pro.config import MAX_CONTEXT_RETRIES, MAX_CALLS_PER_PROJECT, PROJECT_API_CALL_COUNTS
from MassAudit_Pro.core.api_caller import APICaller
from MassAudit_Pro.core.context_resolver import ContextResolver

class VulnerabilityAnalyzer:
    """
    ç®¡ç†Agentic Context Loopï¼ŒåŒ…æ‹¬åˆå§‹è¯·æ±‚ã€AIå“åº”è§£æã€ä¸Šä¸‹æ–‡æ£€ç´¢å’Œé€’å½’å¢å¼ºPromptï¼Œ
    å¹¶å®ç°ä¸Šä¸‹æ–‡é€’å½’ç†”æ–­ã€‚
    """
    def __init__(self, api_caller: APICaller, context_resolver: ContextResolver, project_api_call_counts: Dict[str, int]):
        """
        åˆå§‹åŒ–VulnerabilityAnalyzerã€‚
        :param api_caller: APICallerå®ä¾‹ï¼Œç”¨äºä¸DeepSeek APIäº¤äº’ã€‚
        :param context_resolver: ContextResolverå®ä¾‹ï¼Œç”¨äºæŸ¥æ‰¾ä»£ç ä¸Šä¸‹æ–‡ã€‚
        :param project_api_call_counts: å­˜å‚¨æ¯ä¸ªé¡¹ç›®APIè°ƒç”¨æ¬¡æ•°çš„å­—å…¸ã€‚
        """
        self.api_caller = api_caller
        self.context_resolver = context_resolver
        self.project_api_call_counts = project_api_call_counts
        logging.info("VulnerabilityAnalyzer initialized with APICaller, ContextResolver, and project API call tracking.")

    def _build_initial_prompt(self, initial_code_snippet: str, project_name: str = "", file_path: str = "", line_number: int = 0) -> List[Dict[str, str]]:
        """
        æ„å»ºåˆå§‹çš„AIè¯·æ±‚æ¶ˆæ¯ï¼ŒåŒ…å«ä»£ç ç‰‡æ®µã€JSONæ ¼å¼è¦æ±‚ä»¥åŠPoCç”ŸæˆæŒ‡ä»¤ã€‚
        """
        system_prompt = (
            "ä½ æ˜¯ä¸€ä¸ªç»éªŒä¸°å¯Œçš„é«˜çº§å®‰å…¨æ¶æ„å¸ˆï¼Œä¸“æ³¨äºä»£ç å®¡è®¡å’Œæ¼æ´åˆ†æã€‚\n"
            "ä½ çš„ä»»åŠ¡æ˜¯åˆ†ææä¾›çš„ä»£ç ç‰‡æ®µï¼Œåˆ¤æ–­æ˜¯å¦å­˜åœ¨å®‰å…¨æ¼æ´ã€‚\n"
            "è¯·ä¸¥æ ¼ä»¥JSONæ ¼å¼å“åº”ï¼Œä¸è¦åŒ…å«Markdownæ ‡è®°ã€‚\n"
            "\n"
            "ã€ä»»åŠ¡è¦æ±‚ã€‘\n"
            "1. åˆ¤å®šæ¼æ´: `status` ä¸º `final` æˆ– `need_context`ã€‚\n"
            "2. å®šçº§: `verdict` ä¸º `High`, `Medium`, `Low`, `Safe`ã€‚\n"
            "3. PoCåˆ¤æ–­ (å…³é”®): å¦‚æœ verdict ä¸º High/Mediumï¼Œè¯·åˆ¤æ–­æ˜¯å¦å¯ä»¥é€šè¿‡ Go å•å…ƒæµ‹è¯• (`go test`) è¿›è¡ŒéªŒè¯ã€‚\n"
            "   - é€»è¾‘æ¼æ´ã€Panicã€è¶Šç•Œã€æ­£åˆ™ç»•è¿‡ã€XSS/SQLå­—ç¬¦ä¸²æ„é€ é€šå¸¸å¯æµ‹ã€‚\n"
            "   - ä¾èµ–å¤æ‚å¤–éƒ¨ç¯å¢ƒï¼ˆå¦‚ç‰¹å®šæ•°æ®åº“çŠ¶æ€ã€ä¸­é—´ä»¶ï¼‰çš„é€šå¸¸ä¸å¯æµ‹ã€‚\n"
            "4. ç”Ÿæˆè„šæœ¬: å¦‚æœ `is_testable` ä¸º trueï¼Œè¯·ç¼–å†™ä¸€ä¸ªå®Œæ•´çš„ Go æµ‹è¯•æ–‡ä»¶å†…å®¹ (`_test.go`)ã€‚\n"
            "   - åŒ…å (`package`) å¿…é¡»ä¸åŸæ–‡ä»¶ä¸€è‡´ã€‚\n"
            "   - åŒ…å« `func TestExploit_Auto(t *testing.T)`ã€‚\n"
            "   - ä½¿ç”¨ `defer` å’Œ `recover` æ•è· panicã€‚\n"
            "   - ä»£ç å¿…é¡»è‡ªåŒ…å«ï¼ŒMock å¿…è¦å¯¹è±¡ã€‚\n"
            "\n"
            "ã€å“åº”æ ¼å¼ (JSON)ã€‘\n"
            "å¦‚æœéœ€è¦ä¸Šä¸‹æ–‡: `{\"status\": \"need_context\", \"target_function\": \"...\"}`\n"
            "å¦‚æœå¾—å‡ºç»“è®º: \n"
            "{\n"
            "  \"status\": \"final\",\n"
            "  \"verdict\": \"[high|medium|low|safe]\",\n"
            "  \"reason\": \"...\",\n"
            "  \"is_testable\": true/false,\n"
            "  \"poc_code\": \"å®Œæ•´çš„Goä»£ç å­—ç¬¦ä¸²(å¦‚æœ‰)...\",\n"
            "  \"target_package\": \"æ¨æµ‹çš„åŒ…å\"\n"
            "}"
        )
        user_prompt = (
            f"ã€é¡¹ç›®ä¸Šä¸‹æ–‡ã€‘\n"
            f"é¡¹ç›®: {project_name}\n"
            f"æ–‡ä»¶: {file_path} (è¡Œå·: {line_number})\n"
            f"ã€ä»£ç ç‰‡æ®µã€‘\n"
            f"```\n{initial_code_snippet}\n```\n"
            "è¯·åˆ†æï¼Œå¦‚æœæ— æ³•åˆ¤æ–­ï¼Œè¯·æ˜ç¡®æŒ‡å‡ºéœ€è¦å“ªä¸ªå‡½æ•°æˆ–å˜é‡çš„å®šä¹‰ä½œä¸ºä¸Šä¸‹æ–‡ã€‚"
        )
        return [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]

    def _build_context_prompt(self, messages: List[Dict[str, str]], context_info: List[Dict[str, Any]]) -> List[Dict[str, str]]:
        """
        å°†æ‰¾åˆ°çš„ä¸Šä¸‹æ–‡ä»£ç å—è¿½åŠ åˆ°AIçš„åç»­è¯·æ±‚æ¶ˆæ¯ä¸­ã€‚
        """
        context_string = "\n--- é¢å¤–ä¸Šä¸‹æ–‡ä¿¡æ¯ ---\n"
        for ctx in context_info:
            context_string += (
                f"åœ¨æ–‡ä»¶ `{ctx['file_path']}` ä¸­æ‰¾åˆ°ä»¥ä¸‹ `{ctx['language']}` ä»£ç å—ï¼Œå†…å®¹ä¸º `{ctx['target_name']}` çš„å®šä¹‰ï¼š\n"
                f"```\n{ctx['code_block']}\n```\n"
            )
        context_string += "\nè¯·ç»“åˆä»¥ä¸Šä¸Šä¸‹æ–‡ï¼Œç»§ç»­åˆ†æå¹¶ç»™å‡ºæ¼æ´åˆ¤æ–­ï¼ˆå¦‚ç¡®è®¤ä¸ºé«˜å±ä¸”å¯æµ‹ï¼Œè¯·è®°å¾—ç”Ÿæˆ PoC ä»£ç ï¼‰ã€‚"

        # å°†ä¸Šä¸‹æ–‡è¿½åŠ åˆ°æœ€æ–°çš„ç”¨æˆ·æ¶ˆæ¯ä¸­
        updated_messages = list(messages) # å¤åˆ¶åˆ—è¡¨ä»¥é¿å…ä¿®æ”¹åŸå§‹å¼•ç”¨
        if updated_messages and updated_messages[-1]['role'] == 'user':
            updated_messages[-1]['content'] += context_string
        else: # å¦‚æœæœ€åä¸€ä¸ªä¸æ˜¯ç”¨æˆ·æ¶ˆæ¯ï¼Œæˆ–è€…åˆ—è¡¨ä¸ºç©ºï¼Œåˆ™ä½œä¸ºæ–°ç”¨æˆ·æ¶ˆæ¯æ·»åŠ 
            updated_messages.append({"role": "user", "content": context_string})

        return updated_messages


    def analyze_vulnerability(
        self,
        project_name: str,
        initial_code_snippet: str,
        project_path: str, # For ContextResolver
        file_path: str, # For reporting
        line_number: int # For reporting
    ) -> Dict[str, Any]:
        """
        å®ç°æ ¸å¿ƒçš„â€œAnalyze - Feedback - Refineâ€å¾ªç¯ã€‚
        :param project_name: å½“å‰åˆ†æçš„é¡¹ç›®åç§°ã€‚
        :param initial_code_snippet: åˆå§‹çš„æ¼æ´ç‚¹ä»£ç ç‰‡æ®µã€‚
        :param project_path: é¡¹ç›®çš„ç›¸å¯¹è·¯å¾„ï¼Œç”¨äºä¸Šä¸‹æ–‡æ£€ç´¢ã€‚
        :param file_path: æ¼æ´æ‰€åœ¨æ–‡ä»¶çš„ç›¸å¯¹è·¯å¾„ã€‚
        :param line_number: æ¼æ´æ‰€åœ¨çš„è¡Œå·ã€‚
        :return: AIçš„æœ€ç»ˆåˆ¤æ–­ç»“æœæˆ–å¼ºåˆ¶ç»“è®ºã€‚
        """
        # [ä¿®æ”¹] ä¼ é€’é¡¹ç›®ä¿¡æ¯ç»™ _build_initial_prompt ä»¥ä¾¿ç”Ÿæˆæ›´å¥½çš„ PoC
        current_messages = self._build_initial_prompt(initial_code_snippet, project_name, file_path, line_number)
        
        analysis_log = []
        final_result = {"status": "skipped", "verdict": "unknown", "reason": "Analysis not completed."}

        logging.info(f"[INFO] ğŸ•µï¸ Project {project_name}: Starting analysis for snippet at {file_path}:{line_number}")

        # Initialize project call count if not present
        if project_name not in self.project_api_call_counts:
            self.project_api_call_counts[project_name] = 0

        for retry_count in range(MAX_CONTEXT_RETRIES + 1): # +1 to include the initial request
            current_round_log = {"round": retry_count, "request": current_messages[-1]['content']}

            # --- Project-level API call limit check ---
            if self.project_api_call_counts[project_name] >= MAX_CALLS_PER_PROJECT:
                logging.warning(f"[WARN] âŒ Project {project_name}: Hit API limit ({self.project_api_call_counts[project_name]}/{MAX_CALLS_PER_PROJECT}), stopping analysis for this vulnerability.")
                final_result = {"status": "skipped", "verdict": "SKIPPED_QUOTA_LIMIT", "reason": "Project API call limit exceeded."}
                analysis_log.append(current_round_log) # Log the attempt before hitting limit
                break

            if APICaller._circuit_breaker_tripped: # Check global circuit breaker
                logging.critical(f"[ERROR] Global API circuit breaker tripped. Terminating analysis for {project_name}.")
                final_result = {"status": "aborted", "verdict": "unknown", "reason": "Global API circuit breaker tripped."}
                analysis_log.append(current_round_log) # Log the attempt before global trip
                break

            try:
                logging.info(f"[INFO] ğŸ•µï¸ Project {project_name}: Sending request to AI (Round {retry_count + 1}/{MAX_CONTEXT_RETRIES + 1}) - API Calls for Project: {self.project_api_call_counts[project_name]}/{MAX_CALLS_PER_PROJECT}")
                raw_response = self.api_caller.call_llm(messages=current_messages)
                self.project_api_call_counts[project_name] += 1 # Increment call count after successful API call
                
                current_round_log["raw_response"] = raw_response
                ai_response = json.loads(raw_response)
                current_round_log["parsed_response"] = ai_response

                status = ai_response.get("status")

                if status == "final":
                    logging.info(f"[INFO] ğŸ•µï¸ Project {project_name}: AI reached final conclusion: {ai_response.get('verdict')}")
                    final_result = ai_response
                    break
                elif status == "need_context":
                    target_function = ai_response.get("target_function")
                    if not target_function:
                        logging.warning(f"[WARN] Project {project_name}: AI requested context but 'target_function' was not provided. Forcing conclusion.")
                        final_result = {"status": "final", "verdict": "medium", "reason": "AI requested context but did not specify target_function. Concluding with existing info."}
                        break

                    logging.info(f"[INFO] ğŸ•µï¸ Project {project_name}: AI requested context for '{target_function}'")
                    current_round_log["requested_context"] = target_function

                    context_info = self.context_resolver.resolve_context(project_path, target_function)
                    current_round_log["resolved_context"] = context_info

                    if context_info:
                        logging.info(f"[INFO] ğŸ•µï¸ Project {project_name}: Found {len(context_info)} context blocks for '{target_function}'. Appending to prompt.")
                        # Add the AI's response to messages history
                        current_messages.append({"role": "assistant", "content": raw_response})
                        current_messages = self._build_context_prompt(current_messages, context_info)
                        # Add the new user message asking to continue analysis with context
                        current_messages.append({"role": "user", "content": f"ç»“åˆä¸Šè¿°ä¸Šä¸‹æ–‡ï¼Œè¯·ç»§ç»­åˆ†æï¼š"})
                    else:
                        logging.warning(f"[WARN] Project {project_name}: Could not find context for '{target_function}'. Forcing conclusion.")
                        final_result = {"status": "final", "verdict": "medium", "reason": f"AI requested context for '{target_function}' but it could not be found. Concluding with existing info."}
                        break
                else:
                    logging.error(f"[ERROR] Project {project_name}: AI returned unknown status '{status}'. Forcing conclusion.")
                    final_result = {"status": "final", "verdict": "medium", "reason": f"AI returned unknown status '{status}'. Concluding with existing info."}
                    break # Unknown status, break loop

            except json.JSONDecodeError as e:
                logging.error(f"[ERROR] Project {project_name}: AI response was not valid JSON: {raw_response}. Error: {e}. Forcing conclusion.")
                final_result = {"status": "final", "verdict": "medium", "reason": f"AI returned malformed JSON. Error: {e}. Concluding with existing info."}
                break
            except RuntimeError as e: # Catch circuit breaker trip from APICaller
                logging.error(f"[ERROR] Project {project_name}: API call failed due to {e}. Forcing conclusion.")
                final_result = {"status": "aborted", "verdict": "unknown", "reason": f"API call failed due to {e}."}
                break
            except Exception as e:
                logging.error(f"[ERROR] Project {project_name}: An unexpected error occurred during AI interaction: {e}. Forcing conclusion.")
                final_result = {"status": "final", "verdict": "medium", "reason": f"An unexpected error occurred during AI interaction: {e}. Concluding with existing info."}
                break
            finally:
                analysis_log.append(current_round_log)
                # If the loop breaks due to project limit, the final_result would already be set.
                # If it breaks due to other reasons, and it's not the last retry, we might need to log.

        if retry_count == MAX_CONTEXT_RETRIES and final_result["status"] not in ["final", "aborted", "skipped"]:
            logging.warning(f"[WARN] Project {project_name}: Context recursion limit reached ({MAX_CONTEXT_RETRIES} retries). Forcing AI to provide conclusion.")
            # If limit reached and still not final, make one last call asking for a final verdict
            last_chance_messages = list(current_messages)
            if last_chance_messages and last_chance_messages[-1]['role'] == 'user':
                last_chance_messages[-1]['content'] += "\næ­¤ä¸ºæœ€åä¸€æ¬¡è¯·æ±‚ï¼Œè¯·åŠ¡å¿…æ ¹æ®å·²æœ‰ä¿¡æ¯ç»™å‡ºæœ€ç»ˆæ¼æ´åˆ¤æ–­ï¼ˆåŒ…å« is_testable å’Œ poc_code å­—æ®µï¼‰ã€‚" # Append to last user message
            else:
                last_chance_messages.append({"role": "user", "content": "æ­¤ä¸ºæœ€åä¸€æ¬¡è¯·æ±‚ï¼Œè¯·åŠ¡å¿…æ ¹æ®å·²æœ‰ä¿¡æ¯ç»™å‡ºæœ€ç»ˆæ¼æ´åˆ¤æ–­ï¼ˆåŒ…å« is_testable å’Œ poc_code å­—æ®µï¼‰ã€‚"})

            try:
                raw_response = self.api_caller.call_llm(messages=last_chance_messages)
                self.project_api_call_counts[project_name] += 1 # Increment call count for the last attempt
                ai_response = json.loads(raw_response)
                final_result = ai_response # Assume AI will return final status now
                logging.info(f"[INFO] Project {project_name}: AI provided final conclusion after context limit: {ai_response.get('verdict')}")
            except json.JSONDecodeError as e:
                logging.error(f"[ERROR] Project {project_name}: Final AI response was not valid JSON after context limit: {raw_response}. Error: {e}.")
                final_result = {"status": "final", "verdict": "medium", "reason": "AI returned malformed JSON after context limit. Concluding with existing info."}
            except Exception as e:
                logging.error(f"[ERROR] Project {project_name}: An error occurred during final AI interaction after context limit: {e}.")
                final_result = {"status": "final", "verdict": "medium", "reason": "An error occurred during final AI interaction after context limit. Concluding with existing info."}

        final_result["analysis_log"] = analysis_log
        final_result["file_path"] = file_path
        final_result["line_number"] = line_number

        if not final_result.get("verdict"): # Ensure verdict is always present
            final_result["verdict"] = "unknown"

        return final_result