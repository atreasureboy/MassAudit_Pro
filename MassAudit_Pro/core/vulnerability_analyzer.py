
import json
import logging
from typing import Dict, Any, List, Optional

# Import constants and classes from other modules
from MassAudit_Pro.config import MAX_CONTEXT_RETRIES, MAX_CALLS_PER_PROJECT, PROJECT_API_CALL_COUNTS
from MassAudit_Pro.core.api_caller import APICaller
from MassAudit_Pro.core.context_resolver import ContextResolver

class VulnerabilityAnalyzer:
    """
    ÁÆ°ÁêÜAgentic Context LoopÔºåÂåÖÊã¨ÂàùÂßãËØ∑Ê±Ç„ÄÅAIÂìçÂ∫îËß£Êûê„ÄÅ‰∏ä‰∏ãÊñáÊ£ÄÁ¥¢ÂíåÈÄíÂΩíÂ¢ûÂº∫PromptÔºå
    Âπ∂ÂÆûÁé∞‰∏ä‰∏ãÊñáÈÄíÂΩíÁÜîÊñ≠„ÄÇ
    """
    def __init__(self, api_caller: APICaller, context_resolver: ContextResolver, project_api_call_counts: Dict[str, int]):
        """
        ÂàùÂßãÂåñVulnerabilityAnalyzer„ÄÇ
        :param api_caller: APICallerÂÆû‰æãÔºåÁî®‰∫é‰∏éDeepSeek API‰∫§‰∫í„ÄÇ
        :param context_resolver: ContextResolverÂÆû‰æãÔºåÁî®‰∫éÊü•Êâæ‰ª£Á†Å‰∏ä‰∏ãÊñá„ÄÇ
        :param project_api_call_counts: Â≠òÂÇ®ÊØè‰∏™È°πÁõÆAPIË∞ÉÁî®Ê¨°Êï∞ÁöÑÂ≠óÂÖ∏„ÄÇ
        """
        self.api_caller = api_caller
        self.context_resolver = context_resolver
        self.project_api_call_counts = project_api_call_counts
        logging.info("VulnerabilityAnalyzer initialized with APICaller, ContextResolver, and project API call tracking.")

    def _build_initial_prompt(self, initial_code_snippet: str) -> List[Dict[str, str]]:
        """
        ÊûÑÂª∫ÂàùÂßãÁöÑAIËØ∑Ê±ÇÊ∂àÊÅØÔºåÂåÖÂê´‰ª£Á†ÅÁâáÊÆµÂíåJSONÊ†ºÂºèË¶ÅÊ±Ç„ÄÇ
        """
        system_prompt = (
            "‰Ω†ÊòØ‰∏Ä‰∏™ÁªèÈ™å‰∏∞ÂØåÁöÑÈ´òÁ∫ßÂÆâÂÖ®Êû∂ÊûÑÂ∏àÔºå‰∏ìÊ≥®‰∫é‰ª£Á†ÅÂÆ°ËÆ°ÂíåÊºèÊ¥ûÂàÜÊûê„ÄÇ\n"
            "‰Ω†ÁöÑ‰ªªÂä°ÊòØÂàÜÊûêÊèê‰æõÁöÑ‰ª£Á†ÅÁâáÊÆµÔºåÂà§Êñ≠ÊòØÂê¶Â≠òÂú®ÂÆâÂÖ®ÊºèÊ¥û„ÄÇ\n"
            "ËØ∑‰∏•Ê†º‰ª•JSONÊ†ºÂºèÂìçÂ∫î„ÄÇ\n"
            "Â¶ÇÊûúËÉΩÂà§Êñ≠ÊºèÊ¥ûÔºåËøîÂõû: `{\"status\": \"final\", \"verdict\": \"[high|medium|low|info]\", \"reason\": \"...\"}`\n"
            "Â¶ÇÊûúÈúÄË¶ÅÊõ¥Â§ö‰∏ä‰∏ãÊñáÊâçËÉΩÂà§Êñ≠ÔºåËøîÂõû: `{\"status\": \"need_context\", \"target_function\": \"[ÂáΩÊï∞ÊàñÂèòÈáèÂêç]\"}`\n"
            "Âú®Âà§Êñ≠ÊºèÊ¥ûÊó∂Ôºå‰ºòÂÖàÂØªÊâæInput (Source) Âà∞ Execution (Sink) ÁöÑÂÆåÊï¥Ë∑ØÂæÑ„ÄÇ"
        )
        user_prompt = (
            f"ËØ∑ÂàÜÊûê‰ª•‰∏ã‰ª£Á†ÅÁâáÊÆµÔºåÂà§Êñ≠ÊòØÂê¶Â≠òÂú®ÂÆâÂÖ®ÊºèÊ¥ûÔºö\n"
            f"```\n{initial_code_snippet}\n```\n"
            "Â¶ÇÊûúÊó†Ê≥ïÂà§Êñ≠ÔºåËØ∑ÊòéÁ°ÆÊåáÂá∫ÈúÄË¶ÅÂì™‰∏™ÂáΩÊï∞ÊàñÂèòÈáèÁöÑÂÆö‰πâ‰Ωú‰∏∫‰∏ä‰∏ãÊñá„ÄÇ"
        )
        return [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]

    def _build_context_prompt(self, messages: List[Dict[str, str]], context_info: List[Dict[str, Any]]) -> List[Dict[str, str]]:
        """
        Â∞ÜÊâæÂà∞ÁöÑ‰∏ä‰∏ãÊñá‰ª£Á†ÅÂùóËøΩÂä†Âà∞AIÁöÑÂêéÁª≠ËØ∑Ê±ÇÊ∂àÊÅØ‰∏≠„ÄÇ
        """
        context_string = "\n--- È¢ùÂ§ñ‰∏ä‰∏ãÊñá‰ø°ÊÅØ ---\n"
        for ctx in context_info:
            context_string += (
                f"Âú®Êñá‰ª∂ `{ctx['file_path']}` ‰∏≠ÊâæÂà∞‰ª•‰∏ã `{ctx['language']}` ‰ª£Á†ÅÂùóÔºåÂÜÖÂÆπ‰∏∫ `{ctx['target_name']}` ÁöÑÂÆö‰πâÔºö\n"
                f"```\n{ctx['code_block']}\n```\n"
            )
        context_string += "\nËØ∑ÁªìÂêà‰ª•‰∏ä‰∏ä‰∏ãÊñáÔºåÁªßÁª≠ÂàÜÊûêÂπ∂ÁªôÂá∫ÊºèÊ¥ûÂà§Êñ≠„ÄÇ"

        # Â∞Ü‰∏ä‰∏ãÊñáËøΩÂä†Âà∞ÊúÄÊñ∞ÁöÑÁî®Êà∑Ê∂àÊÅØ‰∏≠
        updated_messages = list(messages) # Â§çÂà∂ÂàóË°®‰ª•ÈÅøÂÖç‰øÆÊîπÂéüÂßãÂºïÁî®
        if updated_messages and updated_messages[-1]['role'] == 'user':
            updated_messages[-1]['content'] += context_string
        else: # Â¶ÇÊûúÊúÄÂêé‰∏Ä‰∏™‰∏çÊòØÁî®Êà∑Ê∂àÊÅØÔºåÊàñËÄÖÂàóË°®‰∏∫Á©∫ÔºåÂàô‰Ωú‰∏∫Êñ∞Áî®Êà∑Ê∂àÊÅØÊ∑ªÂä†
            updated_messages.append({"role": "user", "content": context_string})

        return updated_messages


    def analyze_vulnerability(
        self,
        project_name: str,
        initial_code_snippet: str,
        project_path: str, # For ContextResolver
        file_path: str, # For reporting
        line_number: int # For reporting
    ) -> Dict[str, Any]:
        """
        ÂÆûÁé∞Ê†∏ÂøÉÁöÑ‚ÄúAnalyze - Feedback - Refine‚ÄùÂæ™ÁéØ„ÄÇ
        :param project_name: ÂΩìÂâçÂàÜÊûêÁöÑÈ°πÁõÆÂêçÁß∞„ÄÇ
        :param initial_code_snippet: ÂàùÂßãÁöÑÊºèÊ¥ûÁÇπ‰ª£Á†ÅÁâáÊÆµ„ÄÇ
        :param project_path: È°πÁõÆÁöÑÁõ∏ÂØπË∑ØÂæÑÔºåÁî®‰∫é‰∏ä‰∏ãÊñáÊ£ÄÁ¥¢„ÄÇ
        :param file_path: ÊºèÊ¥ûÊâÄÂú®Êñá‰ª∂ÁöÑÁõ∏ÂØπË∑ØÂæÑ„ÄÇ
        :param line_number: ÊºèÊ¥ûÊâÄÂú®ÁöÑË°åÂè∑„ÄÇ
        :return: AIÁöÑÊúÄÁªàÂà§Êñ≠ÁªìÊûúÊàñÂº∫Âà∂ÁªìËÆ∫„ÄÇ
        """
        current_messages = self._build_initial_prompt(initial_code_snippet)
        analysis_log = []
        final_result = {"status": "skipped", "verdict": "unknown", "reason": "Analysis not completed."}

        logging.info(f"[INFO] üïµÔ∏è Project {project_name}: Starting analysis for snippet at {file_path}:{line_number}")

        # Initialize project call count if not present
        if project_name not in self.project_api_call_counts:
            self.project_api_call_counts[project_name] = 0

        for retry_count in range(MAX_CONTEXT_RETRIES + 1): # +1 to include the initial request
            current_round_log = {"round": retry_count, "request": current_messages[-1]['content']}

            # --- Project-level API call limit check ---
            if self.project_api_call_counts[project_name] >= MAX_CALLS_PER_PROJECT:
                logging.warning(f"[WARN] ‚ùå Project {project_name}: Hit API limit ({self.project_api_call_counts[project_name]}/{MAX_CALLS_PER_PROJECT}), stopping analysis for this vulnerability.")
                final_result = {"status": "skipped", "verdict": "SKIPPED_QUOTA_LIMIT", "reason": "Project API call limit exceeded."}
                analysis_log.append(current_round_log) # Log the attempt before hitting limit
                break

            if APICaller._circuit_breaker_tripped: # Check global circuit breaker
                logging.critical(f"[ERROR] Global API circuit breaker tripped. Terminating analysis for {project_name}.")
                final_result = {"status": "aborted", "verdict": "unknown", "reason": "Global API circuit breaker tripped."}
                analysis_log.append(current_round_log) # Log the attempt before global trip
                break

            try:
                logging.info(f"[INFO] üïµÔ∏è Project {project_name}: Sending request to AI (Round {retry_count + 1}/{MAX_CONTEXT_RETRIES + 1}) - API Calls for Project: {self.project_api_call_counts[project_name]}/{MAX_CALLS_PER_PROJECT}")
                raw_response = self.api_caller.call_llm(messages=current_messages)
                self.project_api_call_counts[project_name] += 1 # Increment call count after successful API call
                
                current_round_log["raw_response"] = raw_response
                ai_response = json.loads(raw_response)
                current_round_log["parsed_response"] = ai_response

                status = ai_response.get("status")

                if status == "final":
                    logging.info(f"[INFO] üïµÔ∏è Project {project_name}: AI reached final conclusion: {ai_response.get('verdict')}")
                    final_result = ai_response
                    break
                elif status == "need_context":
                    target_function = ai_response.get("target_function")
                    if not target_function:
                        logging.warning(f"[WARN] Project {project_name}: AI requested context but 'target_function' was not provided. Forcing conclusion.")
                        final_result = {"status": "final", "verdict": "medium", "reason": "AI requested context but did not specify target_function. Concluding with existing info."}
                        break

                    logging.info(f"[INFO] üïµÔ∏è Project {project_name}: AI requested context for '{target_function}'")
                    current_round_log["requested_context"] = target_function

                    context_info = self.context_resolver.resolve_context(project_path, target_function)
                    current_round_log["resolved_context"] = context_info

                    if context_info:
                        logging.info(f"[INFO] üïµÔ∏è Project {project_name}: Found {len(context_info)} context blocks for '{target_function}'. Appending to prompt.")
                        # Add the AI's response to messages history
                        current_messages.append({"role": "assistant", "content": raw_response})
                        current_messages = self._build_context_prompt(current_messages, context_info)
                        # Add the new user message asking to continue analysis with context
                        current_messages.append({"role": "user", "content": f"ÁªìÂêà‰∏äËø∞‰∏ä‰∏ãÊñáÔºåËØ∑ÁªßÁª≠ÂàÜÊûêÔºö"})
                    else:
                        logging.warning(f"[WARN] Project {project_name}: Could not find context for '{target_function}'. Forcing conclusion.")
                        final_result = {"status": "final", "verdict": "medium", "reason": f"AI requested context for '{target_function}' but it could not be found. Concluding with existing info."}
                        break
                else:
                    logging.error(f"[ERROR] Project {project_name}: AI returned unknown status '{status}'. Forcing conclusion.")
                    final_result = {"status": "final", "verdict": "medium", "reason": f"AI returned unknown status '{status}'. Concluding with existing info."}
                    break # Unknown status, break loop

            except json.JSONDecodeError as e:
                logging.error(f"[ERROR] Project {project_name}: AI response was not valid JSON: {raw_response}. Error: {e}. Forcing conclusion.")
                final_result = {"status": "final", "verdict": "medium", "reason": f"AI returned malformed JSON. Error: {e}. Concluding with existing info."}
                break
            except RuntimeError as e: # Catch circuit breaker trip from APICaller
                logging.error(f"[ERROR] Project {project_name}: API call failed due to {e}. Forcing conclusion.")
                final_result = {"status": "aborted", "verdict": "unknown", "reason": f"API call failed due to {e}."}
                break
            except Exception as e:
                logging.error(f"[ERROR] Project {project_name}: An unexpected error occurred during AI interaction: {e}. Forcing conclusion.")
                final_result = {"status": "final", "verdict": "medium", "reason": f"An unexpected error occurred during AI interaction: {e}. Concluding with existing info."}
                break
            finally:
                analysis_log.append(current_round_log)
                # If the loop breaks due to project limit, the final_result would already be set.
                # If it breaks due to other reasons, and it's not the last retry, we might need to log.

        if retry_count == MAX_CONTEXT_RETRIES and final_result["status"] not in ["final", "aborted", "skipped"]:
            logging.warning(f"[WARN] Project {project_name}: Context recursion limit reached ({MAX_CONTEXT_RETRIES} retries). Forcing AI to provide conclusion.")
            # If limit reached and still not final, make one last call asking for a final verdict
            last_chance_messages = list(current_messages)
            if last_chance_messages and last_chance_messages[-1]['role'] == 'user':
                last_chance_messages[-1]['content'] += "\nÊ≠§‰∏∫ÊúÄÂêé‰∏ÄÊ¨°ËØ∑Ê±ÇÔºåËØ∑Âä°ÂøÖÊ†πÊçÆÂ∑≤Êúâ‰ø°ÊÅØÁªôÂá∫ÊúÄÁªàÊºèÊ¥ûÂà§Êñ≠„ÄÇ" # Append to last user message
            else:
                last_chance_messages.append({"role": "user", "content": "Ê≠§‰∏∫ÊúÄÂêé‰∏ÄÊ¨°ËØ∑Ê±ÇÔºåËØ∑Âä°ÂøÖÊ†πÊçÆÂ∑≤Êúâ‰ø°ÊÅØÁªôÂá∫ÊúÄÁªàÊºèÊ¥ûÂà§Êñ≠„ÄÇ"})

            try:
                raw_response = self.api_caller.call_llm(messages=last_chance_messages)
                self.project_api_call_counts[project_name] += 1 # Increment call count for the last attempt
                ai_response = json.loads(raw_response)
                final_result = ai_response # Assume AI will return final status now
                logging.info(f"[INFO] Project {project_name}: AI provided final conclusion after context limit: {ai_response.get('verdict')}")
            except json.JSONDecodeError as e:
                logging.error(f"[ERROR] Project {project_name}: Final AI response was not valid JSON after context limit: {raw_response}. Error: {e}.")
                final_result = {"status": "final", "verdict": "medium", "reason": "AI returned malformed JSON after context limit. Concluding with existing info."}
            except Exception as e:
                logging.error(f"[ERROR] Project {project_name}: An error occurred during final AI interaction after context limit: {e}.")
                final_result = {"status": "final", "verdict": "medium", "reason": "An error occurred during final AI interaction after context limit. Concluding with existing info."}

        final_result["analysis_log"] = analysis_log
        final_result["file_path"] = file_path
        final_result["line_number"] = line_number

        if not final_result.get("verdict"): # Ensure verdict is always present
            final_result["verdict"] = "unknown"

        return final_result
